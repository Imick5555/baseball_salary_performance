{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af624e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Driver started successfully!\n",
      "'br-salaries' in page? True\n",
      "Lindor Salaries (2016–2031 + future years):\n",
      "Year  Age  Team                     Salary           Service Time\n",
      "---------------------------------------------------------------------------\n",
      "2016  22   Cleveland Indians        $540,300            0.113\n",
      "2017  23   Cleveland Indians        $579,300            1.113\n",
      "2018  24   Cleveland Indians        $623,200            2.113\n",
      "2019  25   Cleveland Indians        $10,850,000         3.113\n",
      "2020  26   Cleveland Indians        $17,500,000         4.113\n",
      "2021  27   New York Mets            $22,300,000         5.113\n",
      "2022  28   New York Mets            $34,100,000         6.113\n",
      "2023  29   New York Mets            $34,100,000         7.113\n",
      "2024  30   New York Mets            $34,100,000         8.113\n",
      "2025  31   New York Mets            $34,100,000         9.113\n",
      "2026  32   New York Mets            $34,100,000  ← future  10.113\n",
      "2027  33   New York Mets            $34,100,000  ← future  \n",
      "2028  34   New York Mets            $34,100,000  ← future  \n",
      "2029  35   New York Mets            $34,100,000  ← future  \n",
      "2030  36   New York Mets            $34,100,000  ← future  \n",
      "2031  37   New York Mets            $34,100,000  ← future  \n",
      "\n",
      "Career total to date: $188,792,800\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import *\n",
    "from bs4 import BeautifulSoup, Comment\n",
    "import time\n",
    "\n",
    "url = \"https://www.baseball-reference.com/players/l/lindofr01.shtml\"\n",
    "CHROMEDRIVER_PATH = r\"C:\\Users\\Isaac\\OneDrive\\Documents\\fall 2025 semester\\STAT 386\\chromedriver-win64\\chromedriver.exe\"\n",
    "OUTPUT_PATH = r\"C:\\Users\\Isaac\\OneDrive\\Documents\\fall 2025 semester\\STAT 386\\MLB_2018_2025_with_Salaries.csv\"\n",
    "hitting_data = pd.read_csv(\"C:\\\\Users\\\\Isaac\\\\OneDrive\\\\Documents\\\\fall 2025 semester\\\\STAT 386\\\\MLB_2018_2025_Cleaned.csv\")\n",
    "\n",
    "URL_COLUMN = \"Player_Link\"\n",
    "YEAR_COLUMN  = \"Year\"\n",
    "\n",
    "hitting_data[\"Salary\"] = 0                # integer version\n",
    "hitting_data[\"Salary_formatted\"] = \"\"\n",
    "\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\"--disable-dev-shm-usage\")\n",
    "options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "options.add_experimental_option('useAutomationExtension', False)\n",
    "\n",
    "service = Service(CHROMEDRIVER_PATH)\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "# Print driver info to confirm version\n",
    "print(\"Driver started successfully!\")\n",
    "\n",
    "driver.get(url)\n",
    "time.sleep(6)\n",
    "\n",
    "page_source = driver.page_source\n",
    "driver.quit()\n",
    "\n",
    "soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "print(\"'br-salaries' in page?\", \"br-salaries\" in page_source)\n",
    "\n",
    "comments = soup.find_all(string=lambda text: isinstance(text, Comment))\n",
    "\n",
    "for comment in comments:\n",
    "    if \"br-salaries\" in comment:\n",
    "        comment_soup = BeautifulSoup(comment, \"html.parser\")\n",
    "        table = comment_soup.find(\"table\", id=\"br-salaries\")\n",
    "        if table:\n",
    "            print(\"Lindor Salaries (2016–2031 + future years):\")\n",
    "            print(\"Year  Age  Team                     Salary           Service Time\")\n",
    "            print(\"-\" * 75)\n",
    "           \n",
    "            for row in table.find(\"tbody\").find_all(\"tr\"):\n",
    "                if row.get(\"class\") and (\"spacer\" in row.get(\"class\") or \"status_head\" in row.get(\"class\")):\n",
    "                    continue\n",
    "                cells = row.find_all([\"th\", \"td\"])\n",
    "                if len(cells) < 4:\n",
    "                    continue\n",
    "                year   = cells[0].get_text(strip=True)\n",
    "                age    = cells[1].get_text(strip=True)\n",
    "                team   = cells[2].get_text(strip=True).replace(\"\\xa0\", \" \")\n",
    "                salary = cells[3].get_text(strip=True)\n",
    "                srv    = cells[4].get_text(strip=True) if len(cells) > 4 else \"\"\n",
    "                if cells[3].get(\"data-future\"):\n",
    "                    salary += \"  ← future\"\n",
    "                print(f\"{year:4}  {age:3}  {team:23}  {salary:18}  {srv}\")\n",
    "           \n",
    "            tfoot = table.find(\"tfoot\")\n",
    "            if tfoot:\n",
    "                total = tfoot.find(\"td\", {\"data-stat\": \"salary_total\"})\n",
    "                if total:\n",
    "                    print(f\"\\nCareer total to date: {total.get_text(strip=True)}\")\n",
    "            break\n",
    "else:\n",
    "    print(\"Salaries table not found in any comment\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77f4092b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 1027 unique players with Playwright (invisible, Cloudflare-proof)\n"
     ]
    },
    {
     "ename": "Error",
     "evalue": "It looks like you are using Playwright Sync API inside the asyncio loop.\nPlease use the Async API instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mError\u001b[39m                                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 44\u001b[39m\n\u001b[32m     41\u001b[39m total = df[\u001b[33m\"\u001b[39m\u001b[33mPlayer_Link\u001b[39m\u001b[33m\"\u001b[39m].nunique()\n\u001b[32m     42\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mStarting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m unique players with Playwright (invisible, Cloudflare-proof)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m \u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msync_playwright\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbrowser\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchromium\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlaunch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheadless\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# truly invisible\u001b[39;49;00m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbrowser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnew_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mMozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m        \u001b[49m\u001b[43mviewport\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwidth\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1920\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mheight\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1080\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m        \u001b[49m\u001b[43mjava_script_enabled\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     50\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Isaac\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\playwright\\sync_api\\_context_manager.py:47\u001b[39m, in \u001b[36mPlaywrightContextManager.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     45\u001b[39m             \u001b[38;5;28mself\u001b[39m._own_loop = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     46\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._loop.is_running():\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m Error(\n\u001b[32m     48\u001b[39m \u001b[38;5;250m                \u001b[39m\u001b[33;03m\"\"\"It looks like you are using Playwright Sync API inside the asyncio loop.\u001b[39;00m\n\u001b[32m     49\u001b[39m \u001b[33;03mPlease use the Async API instead.\"\"\"\u001b[39;00m\n\u001b[32m     50\u001b[39m             )\n\u001b[32m     52\u001b[39m         \u001b[38;5;66;03m# Create a new fiber for the protocol dispatcher. It will be pumping events\u001b[39;00m\n\u001b[32m     53\u001b[39m         \u001b[38;5;66;03m# until the end of times. We will pass control to that fiber every time we\u001b[39;00m\n\u001b[32m     54\u001b[39m         \u001b[38;5;66;03m# block while waiting for a response.\u001b[39;00m\n\u001b[32m     55\u001b[39m         \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgreenlet_main\u001b[39m() -> \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mError\u001b[39m: It looks like you are using Playwright Sync API inside the asyncio loop.\nPlease use the Async API instead."
     ]
    }
   ],
   "source": [
    "# FINAL_REAL_ONE_that_works_dec2025.py\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "from playwright.sync_api import sync_playwright\n",
    "from bs4 import BeautifulSoup, Comment\n",
    "\n",
    "# Prevent computer from sleeping (Windows)\n",
    "os.system('powercfg -change -standby-timeout-ac 0')\n",
    "os.system('powercfg -change -standby-timeout-dc 0')\n",
    "\n",
    "INPUT  = r\"C:\\Users\\Isaac\\OneDrive\\Documents\\fall 2025 semester\\STAT 386\\MLB_2018_2025_Cleaned.csv\"\n",
    "OUTPUT = r\"C:\\Users\\Isaac\\OneDrive\\Documents\\fall 2025 semester\\STAT 386\\MLB_Salaries_2018_2025_FINAL.csv\"\n",
    "\n",
    "# -------------------------------------------------\n",
    "def get_salaries(html):\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    for comment in soup.find_all(string=lambda t: isinstance(t, Comment)):\n",
    "        if \"br-salaries\" in comment:\n",
    "            cs = BeautifulSoup(comment, \"html.parser\")\n",
    "            table = cs.find(\"table\", id=\"br-salaries\")\n",
    "            if table:\n",
    "                sal = {}\n",
    "                for row in table.find_all(\"tr\")[1:]:\n",
    "                    c = row.find_all(\"td\")\n",
    "                    if len(c) >= 4 and c[0].get_text(strip=True).isdigit():\n",
    "                        y = int(c[0].get_text(strip=True))\n",
    "                        if 2018 <= y <= 2025:\n",
    "                            s = c[3].get_text(strip=True).replace(\"$\",\"\").replace(\",\",\"\")\n",
    "                            sal[y] = int(s) if s else 0\n",
    "                return sal\n",
    "    return {}\n",
    "\n",
    "# -------------------------------------------------\n",
    "df = pd.read_csv(INPUT)\n",
    "df = df[df[\"Year\"].between(2018,2025)][[\"Player\",\"Year\",\"Player_Link\"]].reset_index(drop=True)\n",
    "df[\"Player_Link\"] = \"https://www.baseball-reference.com\" + df[\"Player_Link\"].astype(str)\n",
    "\n",
    "cache = {}\n",
    "total = df[\"Player_Link\"].nunique()\n",
    "print(f\"Starting {total} unique players with Playwright (invisible, Cloudflare-proof)\")\n",
    "\n",
    "with sync_playwright() as p:\n",
    "    browser = p.chromium.launch(headless=True)          # truly invisible\n",
    "    context = browser.new_context(\n",
    "        user_agent=\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36\",\n",
    "        viewport={\"width\": 1920, \"height\": 1080},\n",
    "        java_script_enabled=True\n",
    "    )\n",
    "    # This single line is why it never gets Cloudflare blocked\n",
    "    context.add_init_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => false})\")\n",
    "    \n",
    "    page = context.new_page()\n",
    "\n",
    "    for i, link in enumerate(df[\"Player_Link\"].unique(), 1):\n",
    "        name = df[df[\"Player_Link\"] == link][\"Player\"].iloc[0]\n",
    "        if i <= 5 or i % 50 == 0:\n",
    "            print(f\"{i:4d}/{total} → {name}\")\n",
    "\n",
    "        try:\n",
    "            page.goto(link, wait_until=\"domcontentloaded\", timeout=30000)\n",
    "            page.evaluate(\"window.scrollTo(0, document.body.scrollHeight)\")\n",
    "            time.sleep(1.8)\n",
    "            salaries = get_salaries(page.content())\n",
    "            for n in df[df[\"Player_Link\"]==link][\"Player\"].unique():\n",
    "                cache[n] = salaries\n",
    "        except Exception as e:\n",
    "            print(f\"   failed {name} → will be 0\")\n",
    "        \n",
    "        time.sleep(random.uniform(0.9, 2.1))   # 30–50 players per minute\n",
    "\n",
    "    browser.close()\n",
    "\n",
    "# restore normal sleep\n",
    "os.system('powercfg -change -standby-timeout-ac 15')\n",
    "os.system('powercfg -change -standby-timeout-dc 5')\n",
    "\n",
    "df[\"Salary\"] = df.apply(lambda r: cache.get(r[\"Player\"], {}).get(r[\"Year\"], 0), axis=1)\n",
    "df[\"Salary_Formatted\"] = df[\"Salary\"].apply(lambda x: f\"${x:,}\" if x > 0 else \"\")\n",
    "df[[\"Player\",\"Year\",\"Salary_Formatted\"]].to_csv(OUTPUT, index=False)\n",
    "\n",
    "print(\"\\n100 % DONE – NO MORE CLOUDFLARE PROBLEMS EVER AGAIN\")\n",
    "input(\"Press Enter to close...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e903674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Total rows to enrich: 3518\n",
      "Starting salary scraping... (this will take ~20–30 minutes)\n",
      "Unique player pages to visit: 1027\n",
      "   Retry 2 for Francisco Lindor: Message: timeout: Timed out receiving message from\n",
      "   Failed after 3 tries: Whit Merrifield\n",
      "   Failed after 3 tries: Charlie Blackmon\n",
      "   20/1027 → Carlos Santana\n",
      "   Failed after 3 tries: Carlos Santana\n",
      "   Retry 2 for Khris Davis: Message: timeout: Timed out receiving message from\n",
      "   Retry 1 for Christian Yelich: Message: timeout: Timed out receiving message from\n",
      "   40/1027 → Javier BÃ¡ez\n",
      "   Retry 1 for Michael Brantley: Message: \n",
      "\n",
      "   60/1027 → Adam Jones\n",
      "   Retry 2 for Stephen Piscotty: Message: timeout: Timed out receiving message from\n",
      "   Failed after 3 tries: OdÃºbel Herrera\n",
      "   ↻ Driver restarted\n",
      "   Retry 2 for Brandon Crawford: Message: timeout: Timed out receiving message from\n",
      "   80/1027 → Eddie Rosario\n",
      "   Failed after 3 tries: DJ LeMahieu\n",
      "   Retry 1 for Xander Bogaerts: Message: timeout: Timed out receiving message from\n",
      "   Failed after 3 tries: Joey Gallo\n",
      "   Retry 1 for Yuli Gurriel: Message: timeout: Timed out receiving message from\n",
      "   100/1027 → Nick Ahmed\n",
      "   120/1027 → Corey Dickerson\n",
      "   Retry 2 for Alcides Escobar: Message: timeout: Timed out receiving message from\n",
      "   Retry 1 for Tucker Barnhart: Message: timeout: Timed out receiving message from\n",
      "   Retry 2 for Jonathan Villar: Message: timeout: Timed out receiving message from\n",
      "   Failed after 3 tries: Carlos GonzÃ¡lez\n",
      "   140/1027 → Yadier Molina\n",
      "   Failed after 3 tries: Denard Span\n",
      "   Retry 2 for Jonathan Schoop: Message: timeout: Timed out receiving message from\n",
      "   Retry 2 for Juan Soto: Message: timeout: Timed out receiving message from\n",
      "   ↻ Driver restarted\n",
      "   Retry 1 for Paul DeJong: HTTPConnectionPool(host='localhost', port=57822): \n",
      "   Retry 2 for Paul DeJong: HTTPConnectionPool(host='localhost', port=57822): \n",
      "   Failed after 3 tries: Paul DeJong\n",
      "   Retry 1 for Rafael Devers: HTTPConnectionPool(host='localhost', port=57822): \n",
      "   Retry 2 for Rafael Devers: HTTPConnectionPool(host='localhost', port=57822): \n",
      "   Failed after 3 tries: Rafael Devers\n",
      "   Retry 1 for Jason Heyward: HTTPConnectionPool(host='localhost', port=57822): \n",
      "   Retry 2 for Jason Heyward: HTTPConnectionPool(host='localhost', port=57822): \n",
      "   Failed after 3 tries: Jason Heyward\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup, Comment\n",
    "import time\n",
    "import random\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "INPUT_CSV  = r\"C:\\Users\\Isaac\\OneDrive\\Documents\\fall 2025 semester\\STAT 386\\MLB_2018_2025_Cleaned.csv\"\n",
    "OUT_CSV    = r\"C:\\Users\\Isaac\\OneDrive\\Documents\\fall 2025 semester\\STAT 386\\MLB_Salaries_2018_2025_FINAL.csv\"\n",
    "DRIVER     = r\"C:\\Users\\Isaac\\OneDrive\\Documents\\fall 2025 semester\\STAT 386\\chromedriver-win64\\chromedriver.exe\"\n",
    "\n",
    "# ---------------- DRIVER SETUP ----------------\n",
    "def make_driver():\n",
    "    opts = Options()\n",
    "    opts.add_argument(\"--headless\")\n",
    "    opts.add_argument(\"--no-sandbox\")\n",
    "    opts.add_argument(\"--disable-dev-shm-usage\")\n",
    "    opts.add_argument(\"--disable-gpu\")\n",
    "    opts.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    opts.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    opts.add_experimental_option(\"useAutomationExtension\", False)\n",
    "    driver = webdriver.Chrome(service=Service(DRIVER), options=opts)\n",
    "    driver.set_page_load_timeout(25)\n",
    "    driver.implicitly_wait(10)\n",
    "    return driver\n",
    "\n",
    "# ---------------- EXTRACT SALARIES FROM PAGE ----------------\n",
    "def get_player_salaries_2018_2025(html):\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    salaries = {}\n",
    "\n",
    "    # Method 1: ALWAYS start with comments (this is where EVERY table lives in 2025)\n",
    "    for comment in soup.find_all(string=lambda text: isinstance(text, Comment)):\n",
    "        if \"all_br-salaries\" in str(comment) or \"br-salaries\" in str(comment):\n",
    "            comment_soup = BeautifulSoup(comment, \"html.parser\")\n",
    "            table = comment_soup.find(\"table\", {\"id\": \"br-salaries\"})\n",
    "            if table:\n",
    "                for row in table.find_all(\"tr\")[1:]:  # skip header\n",
    "                    cells = row.find_all(\"td\")\n",
    "                    if len(cells) >= 4:\n",
    "                        year_text = cells[0].get_text(strip=True)\n",
    "                        salary_text = cells[3].get_text(strip=True).replace(\"$\", \"\").replace(\",\", \"\")\n",
    "                        if year_text.isdigit() and 2018 <= int(year_text) <= 2025:\n",
    "                            try:\n",
    "                                salaries[int(year_text)] = int(salary_text) if salary_text else 0\n",
    "                            except:\n",
    "                                salaries[int(year_text)] = 0\n",
    "                break  # found the table\n",
    "    if salaries:\n",
    "        return salaries\n",
    "\n",
    "    # Method 2: Fallback to direct DOM (rare, but covers any JS-injected cases)\n",
    "    table = soup.find(\"table\", {\"id\": \"br-salaries\"})\n",
    "    if table:\n",
    "        for row in table.find_all(\"tr\")[1:]:  # skip header\n",
    "            cells = row.find_all(\"td\")\n",
    "            if len(cells) >= 4:\n",
    "                year_text = cells[0].get_text(strip=True)\n",
    "                salary_text = cells[3].get_text(strip=True).replace(\"$\", \"\").replace(\",\", \"\")\n",
    "                if year_text.isdigit() and 2018 <= int(year_text) <= 2025:\n",
    "                    try:\n",
    "                        salaries[int(year_text)] = int(salary_text) if salary_text else 0\n",
    "                    except:\n",
    "                        salaries[int(year_text)] = 0\n",
    "    return salaries\n",
    "\n",
    "# ---------------- MAIN ----------------\n",
    "print(\"Loading dataset...\")\n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "\n",
    "# Keep only 2018–2025\n",
    "df = df[df[\"Year\"].between(2018, 2025)].copy()\n",
    "df = df[[\"Player\", \"Year\", \"Player_Link\"]].reset_index(drop=True)\n",
    "\n",
    "# Fix links\n",
    "df[\"Player_Link\"] = df[\"Player_Link\"].apply(\n",
    "    lambda x: \"https://www.baseball-reference.com\" + x if str(x).startswith(\"/\") else str(x)\n",
    ")\n",
    "\n",
    "print(f\"Total rows to enrich: {len(df)}\")\n",
    "print(\"Starting salary scraping... (this will take ~20–30 minutes)\")\n",
    "\n",
    "# We'll store salaries here: {player_name: {year: salary}}\n",
    "player_salary_cache = {}\n",
    "driver = make_driver()\n",
    "\n",
    "try:\n",
    "    unique_links = df[\"Player_Link\"].unique()\n",
    "    print(f\"Unique player pages to visit: {len(unique_links)}\")\n",
    "\n",
    "    for i, link in enumerate(unique_links):\n",
    "        players_using_this_link = df[df[\"Player_Link\"] == link][\"Player\"].unique()\n",
    "        player_name = players_using_this_link[0]  # use first as display name\n",
    "\n",
    "        if (i + 1) % 20 == 0:\n",
    "            print(f\"   {i+1}/{len(unique_links)} → {player_name}\")\n",
    "\n",
    "        # Restart driver every 75 players\n",
    "        if (i + 1) % 75 == 0:\n",
    "            driver.quit()\n",
    "            time.sleep(3)\n",
    "            driver = make_driver()\n",
    "            print(\"   ↻ Driver restarted\")\n",
    "\n",
    "        salaries = {}\n",
    "        for attempt in range(3):\n",
    "            try:\n",
    "                driver.get(link)\n",
    "                WebDriverWait(driver, 20).until(lambda d: d.execute_script(\"return document.readyState\") == \"complete\")\n",
    "\n",
    "                # Scroll to bottom to ensure full page source (triggers any lazy-load of comments)\n",
    "                driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                time.sleep(3)\n",
    "\n",
    "                salaries = get_player_salaries_2018_2025(driver.page_source)\n",
    "                if salaries:  # got data\n",
    "                    break\n",
    "\n",
    "            except Exception as e:\n",
    "                if attempt < 2:\n",
    "                    print(f\"   Retry {attempt+1} for {player_name}: {str(e)[:50]}\")\n",
    "                    time.sleep(10)\n",
    "                else:\n",
    "                    print(f\"   Failed after 3 tries: {player_name}\")\n",
    "\n",
    "        # Cache results for all players sharing this link\n",
    "        for name in players_using_this_link:\n",
    "            player_salary_cache[name] = salaries\n",
    "\n",
    "        time.sleep(random.uniform(1.2, 2.8))\n",
    "\n",
    "finally:\n",
    "    driver.quit()\n",
    "\n",
    "# ---------------- APPLY SALARIES BACK IN ORIGINAL ORDER ----------------\n",
    "print(\"Applying salaries to original dataset...\")\n",
    "df[\"Salary\"] = df.apply(\n",
    "    lambda row: player_salary_cache.get(row[\"Player\"], {}).get(row[\"Year\"], 0),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df[\"Salary_Formatted\"] = df[\"Salary\"].apply(lambda x: f\"${x:,}\" if x > 0 else \"\")\n",
    "\n",
    "# Final output — exactly your original row order!\n",
    "final = df[[\"Player\", \"Year\", \"Salary_Formatted\"]].copy()\n",
    "\n",
    "final.to_csv(OUT_CSV, index=False)\n",
    "\n",
    "print(\"\\nDONE! 100% complete.\")\n",
    "print(f\"Saved {len(final):,} rows → {OUT_CSV}\")\n",
    "print(\"\\nFirst 10 rows:\")\n",
    "print(final.head(10).to_string(index=False))\n",
    "\n",
    "print(\"\\nTop 10 highest paid (2018–2025):\")\n",
    "top10 = final.copy()\n",
    "top10[\"Salary_Num\"] = top10[\"Salary_Formatted\"].str.replace(r\"[$,]\", \"\", regex=True).fillna(\"0\").astype(int)\n",
    "print(top10.nlargest(10, \"Salary_Num\")[[\"Player\", \"Year\", \"Salary_Formatted\"]].to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
